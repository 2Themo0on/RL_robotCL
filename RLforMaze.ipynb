{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Env\n",
    "class MultiGoalEnvWithObstacles(gym.Env):\n",
    "    def __init__(self, grid_size=10, num_goals=3, num_obstacles=5):\n",
    "        super(MultiGoalEnvWithObstacles, self).__init__()\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        self.num_goals = num_goals\n",
    "        self.num_obstacles = num_obstacles\n",
    "        \n",
    "        self.action_space = spaces.Discrete(4)  # 상, 하, 좌, 우\n",
    "        self.observation_space = spaces.Box(low=0, high=grid_size-1, shape=(2,), dtype=np.int32)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.robot_pos = np.array([0, 0])\n",
    "        self.goals = self._generate_non_overlapping_positions(self.num_goals)\n",
    "        self.obstacles = self._generate_non_overlapping_positions(self.num_obstacles, self.goals)\n",
    "        self.visited_goals = set()\n",
    "        self.steps = 0\n",
    "        return self.robot_pos, {}\n",
    "\n",
    "    def _generate_non_overlapping_positions(self, num_positions, exclude_positions=[]):\n",
    "        positions = set(exclude_positions)\n",
    "        while len(positions) < num_positions + len(exclude_positions):\n",
    "            pos = tuple(np.random.randint(0, self.grid_size, size=2))\n",
    "            if pos != (0, 0):  # 로봇의 초기 위치 제외\n",
    "                positions.add(pos)\n",
    "        return list(positions - set(exclude_positions))\n",
    "\n",
    "    def step(self, action):\n",
    "            new_pos = self.robot_pos.copy()\n",
    "            if action == 0:\n",
    "                new_pos[1] += 1  # 상\n",
    "            elif action == 1:\n",
    "                new_pos[1] -= 1  # 하\n",
    "            elif action == 2:\n",
    "                new_pos[0] -= 1  # 좌\n",
    "            elif action == 3:\n",
    "                new_pos[0] += 1  # 우\n",
    "\n",
    "            # 그리드 경계를 벗어나지 않도록 처리\n",
    "            new_pos = np.clip(new_pos, 0, self.grid_size-1)\n",
    "            \n",
    "            # 장애물에 부딪히지 않도록 처리\n",
    "            if tuple(new_pos) not in self.obstacles:\n",
    "                self.robot_pos = new_pos\n",
    "            \n",
    "            self.steps += 1\n",
    "            \n",
    "            reward = -1  # 기본 보상은 -1\n",
    "            if tuple(new_pos) in self.obstacles:\n",
    "                reward = -5  # 장애물에 부딪힐 경우 패널티\n",
    "            for i, goal in enumerate(self.goals):\n",
    "                if np.array_equal(self.robot_pos, goal):\n",
    "                    reward = 20  # 목표 지점 도달 시 보상 증가\n",
    "                    self.visited_goals.add(i)\n",
    "            \n",
    "            done = len(self.visited_goals) == self.num_goals or self.steps >= 100  # 모든 목표를 방문하거나 최대 스텝 수를 넘으면 종료\n",
    "            \n",
    "            return self.robot_pos, reward, done, {}, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -79.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 2915     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.6        |\n",
      "|    ep_rew_mean          | -81.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297662 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00132     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.6        |\n",
      "|    ep_rew_mean          | -72.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1070        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006567423 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00927     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98          |\n",
      "|    ep_rew_mean          | -69         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 986         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944719 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.1        |\n",
      "|    ep_rew_mean          | -63.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 950         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008223599 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00526     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.8        |\n",
      "|    ep_rew_mean          | -47.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 927         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007824233 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 485         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98          |\n",
      "|    ep_rew_mean          | -48.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 911         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011141927 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 796         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.3        |\n",
      "|    ep_rew_mean          | -50.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 903         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006978387 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.7         |\n",
      "|    ep_rew_mean          | -50.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 898          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061607007 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.4        |\n",
      "|    ep_rew_mean          | -58.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008605831 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.0213     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.1         |\n",
      "|    ep_rew_mean          | -62.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070592854 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 270          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 401          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.1        |\n",
      "|    ep_rew_mean          | -61.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 882         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010510701 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 97.9         |\n",
      "|    ep_rew_mean          | -60.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 881          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039943047 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 342          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 98.2       |\n",
      "|    ep_rew_mean          | -50.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 878        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00797763 |\n",
      "|    clip_fraction        | 0.0313     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.0573     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 121        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00264   |\n",
      "|    value_loss           | 363        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.4         |\n",
      "|    ep_rew_mean          | -49.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 878          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079538105 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.0544       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 440          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000998    |\n",
      "|    value_loss           | 883          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.4         |\n",
      "|    ep_rew_mean          | -49.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 879          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077962526 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.0822       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.4        |\n",
      "|    ep_rew_mean          | -34.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 878         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007414071 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.0659      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 510         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99           |\n",
      "|    ep_rew_mean          | -37.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 876          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062585752 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.0673       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 443          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.5        |\n",
      "|    ep_rew_mean          | -33.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 874         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162095 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 364         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.2        |\n",
      "|    ep_rew_mean          | -38.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 869         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010411091 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    value_loss           | 825         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.5        |\n",
      "|    ep_rew_mean          | -46.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 866         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006065065 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.249      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.5        |\n",
      "|    ep_rew_mean          | -63.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 861         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005509448 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.0131     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 98.8       |\n",
      "|    ep_rew_mean          | -66.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 857        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00699517 |\n",
      "|    clip_fraction        | 0.0443     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.0295     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 157        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00379   |\n",
      "|    value_loss           | 266        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.3        |\n",
      "|    ep_rew_mean          | -63.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 855         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008712677 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.0447      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 429         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 683         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99          |\n",
      "|    ep_rew_mean          | -59.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 852         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006286959 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m     20\u001b[0m obs, rewards, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 21\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# 줄 바꿈을 추가하여 각 스텝을 구분\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\RL_robotCL\\rlpjt\\Lib\\site-packages\\gymnasium\\core.py:196\u001b[0m, in \u001b[0;36mEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the render frames as specified by :attr:`render_mode` during the initialization of the environment.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    The environment's :attr:`metadata` render modes (`env.metadata[\"render_modes\"]`) should contain the possible\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        in the environment initialised, i.e., ``gymnasium.make(\"CartPole-v1\", render_mode=\"human\")``\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# 환경 생성\n",
    "env = MultiGoalEnvWithObstacles(grid_size=10, num_goals=3, num_obstacles=5)\n",
    "\n",
    "# 모델 생성\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# 모델 학습\n",
    "model.learn(total_timesteps=50000)  # 학습 시간을 50000으로 증가\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"ppo_robot_vacuum_multi_goal_obstacles\")\n",
    "\n",
    "# 모델 로드 및 평가\n",
    "model = PPO.load(\"ppo_robot_vacuum_multi_goal_obstacles\")\n",
    "obs, _ = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    print()  # 줄 바꿈을 추가하여 각 스텝을 구분\n",
    "    if done or truncated:\n",
    "        obs, _ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlpjt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
